{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hayaa-1/Supervised-Machine-Learning/blob/main/weather_forcasting_rain_tomorrow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a03a0b52",
      "metadata": {
        "id": "a03a0b52"
      },
      "source": [
        "# <font color = darkred> Machine Learning I (Final Project) (Due June 12, 2022)</font>\n",
        "## Task #1:\n",
        "### Objective:\n",
        "• The objective of this project is to analyze the weather data and extract the hypotheses to arrive at a prediction<br>\n",
        "• You need to perform at least one classification task of your choice and one regression task in your project.<br> \n",
        "<b>Dataset:</b> weather prediction dataset(weatherHistory.csv)<br> \n",
        "• Available at: https://github.com/martandsingh/datasets/blob/master/weatherHistory.csv<br>\n",
        "• https://www.kaggle.com/datasets/zaraavagyan/weathercsv<br>\n",
        "The dataset consists of different attributes describing the weather condition such as temperature, humidity, pressure…etc.<br>\n",
        "You are requested to do the following for both the regression and classification problems:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58389f3",
      "metadata": {
        "id": "a58389f3"
      },
      "source": [
        "<b>Task 1-a: Classification<font color =darkgreen>Target: Precip Type (snow/rain) , score: F1_score </font> </b><br> \n",
        "1- Load the data and perform all necessary data cleaning and scaling.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c3540e",
      "metadata": {
        "id": "d5c3540e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cabdcbe7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "cabdcbe7",
        "outputId": "eb8bb055-d084-4230-d145-04c0d6fae894"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>...</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>24.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>6.3</td>\n",
              "      <td>NW</td>\n",
              "      <td>30.0</td>\n",
              "      <td>SW</td>\n",
              "      <td>NW</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>29</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>14.4</td>\n",
              "      <td>23.6</td>\n",
              "      <td>No</td>\n",
              "      <td>3.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.0</td>\n",
              "      <td>26.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>9.7</td>\n",
              "      <td>ENE</td>\n",
              "      <td>39.0</td>\n",
              "      <td>E</td>\n",
              "      <td>W</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>1012.4</td>\n",
              "      <td>1008.4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>17.5</td>\n",
              "      <td>25.7</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.7</td>\n",
              "      <td>23.4</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NW</td>\n",
              "      <td>85.0</td>\n",
              "      <td>N</td>\n",
              "      <td>NNE</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>1009.5</td>\n",
              "      <td>1007.2</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>15.4</td>\n",
              "      <td>20.2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>39.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.3</td>\n",
              "      <td>15.5</td>\n",
              "      <td>39.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>9.1</td>\n",
              "      <td>NW</td>\n",
              "      <td>54.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>W</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>56</td>\n",
              "      <td>1005.5</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>13.5</td>\n",
              "      <td>14.1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.6</td>\n",
              "      <td>16.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>10.6</td>\n",
              "      <td>SSE</td>\n",
              "      <td>50.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>ESE</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>49</td>\n",
              "      <td>1018.3</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>11.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>9.0</td>\n",
              "      <td>30.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>12.1</td>\n",
              "      <td>NNW</td>\n",
              "      <td>76.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>NW</td>\n",
              "      <td>7.0</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>1016.1</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>7.1</td>\n",
              "      <td>28.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>12.7</td>\n",
              "      <td>N</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NNW</td>\n",
              "      <td>NNW</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>1016.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17.2</td>\n",
              "      <td>28.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>12.5</td>\n",
              "      <td>19.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>5.3</td>\n",
              "      <td>ESE</td>\n",
              "      <td>43.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>ENE</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>47</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1022.8</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18.3</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>12.5</td>\n",
              "      <td>26.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>NW</td>\n",
              "      <td>46.0</td>\n",
              "      <td>SSW</td>\n",
              "      <td>WNW</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>39</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>1016.2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>15.8</td>\n",
              "      <td>25.9</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>12.3</td>\n",
              "      <td>30.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>NW</td>\n",
              "      <td>78.0</td>\n",
              "      <td>NW</td>\n",
              "      <td>WNW</td>\n",
              "      <td>31.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>1009.6</td>\n",
              "      <td>1009.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>23.8</td>\n",
              "      <td>28.6</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>366 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
              "0        8.0     24.3       0.0          3.4       6.3          NW   \n",
              "1       14.0     26.9       3.6          4.4       9.7         ENE   \n",
              "2       13.7     23.4       3.6          5.8       3.3          NW   \n",
              "3       13.3     15.5      39.8          7.2       9.1          NW   \n",
              "4        7.6     16.1       2.8          5.6      10.6         SSE   \n",
              "..       ...      ...       ...          ...       ...         ...   \n",
              "361      9.0     30.7       0.0          7.6      12.1         NNW   \n",
              "362      7.1     28.4       0.0         11.6      12.7           N   \n",
              "363     12.5     19.9       0.0          8.4       5.3         ESE   \n",
              "364     12.5     26.9       0.0          5.0       7.1          NW   \n",
              "365     12.3     30.2       0.0          6.0      12.6          NW   \n",
              "\n",
              "     WindGustSpeed WindDir9am WindDir3pm  WindSpeed9am  ...  Humidity3pm  \\\n",
              "0             30.0         SW         NW           6.0  ...           29   \n",
              "1             39.0          E          W           4.0  ...           36   \n",
              "2             85.0          N        NNE           6.0  ...           69   \n",
              "3             54.0        WNW          W          30.0  ...           56   \n",
              "4             50.0        SSE        ESE          20.0  ...           49   \n",
              "..             ...        ...        ...           ...  ...          ...   \n",
              "361           76.0        SSE         NW           7.0  ...           15   \n",
              "362           48.0        NNW        NNW           2.0  ...           22   \n",
              "363           43.0        ENE        ENE          11.0  ...           47   \n",
              "364           46.0        SSW        WNW           6.0  ...           39   \n",
              "365           78.0         NW        WNW          31.0  ...           13   \n",
              "\n",
              "     Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  \\\n",
              "0         1019.7       1015.0         7         7     14.4     23.6   \n",
              "1         1012.4       1008.4         5         3     17.5     25.7   \n",
              "2         1009.5       1007.2         8         7     15.4     20.2   \n",
              "3         1005.5       1007.0         2         7     13.5     14.1   \n",
              "4         1018.3       1018.5         7         7     11.1     15.4   \n",
              "..           ...          ...       ...       ...      ...      ...   \n",
              "361       1016.1       1010.8         1         3     20.4     30.0   \n",
              "362       1020.0       1016.9         0         1     17.2     28.2   \n",
              "363       1024.0       1022.8         3         2     14.5     18.3   \n",
              "364       1021.0       1016.2         6         7     15.8     25.9   \n",
              "365       1009.6       1009.2         1         1     23.8     28.6   \n",
              "\n",
              "     RainToday  RISK_MM RainTomorrow  \n",
              "0           No      3.6          Yes  \n",
              "1          Yes      3.6          Yes  \n",
              "2          Yes     39.8          Yes  \n",
              "3          Yes      2.8          Yes  \n",
              "4          Yes      0.0           No  \n",
              "..         ...      ...          ...  \n",
              "361         No      0.0           No  \n",
              "362         No      0.0           No  \n",
              "363         No      0.0           No  \n",
              "364         No      0.0           No  \n",
              "365         No      0.0           No  \n",
              "\n",
              "[366 rows x 22 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('weather1.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0c9deb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0c9deb2",
        "outputId": "19571cda-f036-40e6-8651-22d09e9acf0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 366 entries, 0 to 365\n",
            "Data columns (total 22 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   MinTemp        366 non-null    float64\n",
            " 1   MaxTemp        366 non-null    float64\n",
            " 2   Rainfall       366 non-null    float64\n",
            " 3   Evaporation    366 non-null    float64\n",
            " 4   Sunshine       363 non-null    float64\n",
            " 5   WindGustDir    363 non-null    object \n",
            " 6   WindGustSpeed  364 non-null    float64\n",
            " 7   WindDir9am     335 non-null    object \n",
            " 8   WindDir3pm     365 non-null    object \n",
            " 9   WindSpeed9am   359 non-null    float64\n",
            " 10  WindSpeed3pm   366 non-null    int64  \n",
            " 11  Humidity9am    366 non-null    int64  \n",
            " 12  Humidity3pm    366 non-null    int64  \n",
            " 13  Pressure9am    366 non-null    float64\n",
            " 14  Pressure3pm    366 non-null    float64\n",
            " 15  Cloud9am       366 non-null    int64  \n",
            " 16  Cloud3pm       366 non-null    int64  \n",
            " 17  Temp9am        366 non-null    float64\n",
            " 18  Temp3pm        366 non-null    float64\n",
            " 19  RainToday      366 non-null    object \n",
            " 20  RISK_MM        366 non-null    float64\n",
            " 21  RainTomorrow   366 non-null    object \n",
            "dtypes: float64(12), int64(5), object(5)\n",
            "memory usage: 63.0+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "017499fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "017499fe",
        "outputId": "3e39b456-254c-4904-8fbf-418be346373c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f861993",
      "metadata": {
        "id": "0f861993"
      },
      "outputs": [],
      "source": [
        "data = data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c25f5207",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c25f5207",
        "outputId": "d42b7481-045d-4215-c568-ca781a77de0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MinTemp           0\n",
              "MaxTemp           0\n",
              "Rainfall          0\n",
              "Evaporation       0\n",
              "Sunshine          3\n",
              "WindGustDir       3\n",
              "WindGustSpeed     2\n",
              "WindDir9am       31\n",
              "WindDir3pm        1\n",
              "WindSpeed9am      7\n",
              "WindSpeed3pm      0\n",
              "Humidity9am       0\n",
              "Humidity3pm       0\n",
              "Pressure9am       0\n",
              "Pressure3pm       0\n",
              "Cloud9am          0\n",
              "Cloud3pm          0\n",
              "Temp9am           0\n",
              "Temp3pm           0\n",
              "RainToday         0\n",
              "RISK_MM           0\n",
              "RainTomorrow      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9daf167e",
      "metadata": {
        "id": "9daf167e"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3f6ffdb",
      "metadata": {
        "id": "e3f6ffdb"
      },
      "source": [
        "__________________________\n",
        "2- Data inspection. Use any relevant functions that can help you to understand the data. Use any necessary visualization techniques to inspect your data<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c06ca11",
      "metadata": {
        "id": "9c06ca11"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Spliting the data to train and test data sets\n",
        "traindf , testdf = train_test_split(data, test_size = 0.2, random_state=2022)\n",
        "                                     # in other Scenario we can split it with date(using old data to predict new data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f56c84fb",
      "metadata": {
        "id": "f56c84fb"
      },
      "outputs": [],
      "source": [
        "X_train = traindf.drop('RainTomorrow', axis =1)\n",
        "y_train = (traindf['RainTomorrow']=='Yes').astype(int)\n",
        "X_test = testdf.drop('RainTomorrow', axis =1)\n",
        "y_test = (testdf['RainTomorrow']=='Yes').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd48e953",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd48e953",
        "outputId": "2924fb3a-0547-4365-a761-23d3c74e3aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "#Repeated cols\n",
        "def find_repeated_cols(data , max_repetition):\n",
        "    #find the maximum allowed number of rows allowed to have the same value \n",
        "    max_allowed = max_repetition * data.shape[0]\n",
        "    \n",
        "    cols = list(data.columns)\n",
        "    repeated = []\n",
        "    \n",
        "    for i in cols:\n",
        "        if data[i].value_counts().iloc[0] > max_allowed:\n",
        "            repeated.append(i)\n",
        "            \n",
        "    return repeated\n",
        "to_drop = find_repeated_cols(X_train,0.9)\n",
        "X_train = X_train.drop(to_drop, axis=1)\n",
        "X_test = X_test.drop(to_drop, axis=1)\n",
        "print(to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db3e2d78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db3e2d78",
        "outputId": "dd3e440d-2e6d-4b91-e77c-706a509c945c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 'RISK_MM']\n",
            "['WindDir3pm', 'WindGustDir', 'RainToday', 'WindDir9am']\n"
          ]
        }
      ],
      "source": [
        "cols = X_train.columns\n",
        "num_cols = list(X_train.describe().columns)\n",
        "cat_cols = list(set(cols)-set(num_cols))\n",
        "print(num_cols)\n",
        "print(cat_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dbe35ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dbe35ec",
        "outputId": "1bb1cdca-d2c5-4223-aafd-65f2fa823fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Humidity3pm', 'Temp9am', 'MaxTemp', 'Pressure9am', 'Temp3pm']\n"
          ]
        }
      ],
      "source": [
        "def find_corr_cols(X,y, num_cols ,corr_th):\n",
        "    corr_matrix = X[num_cols].corr()\n",
        "    corr_cols = []\n",
        "    for i in range(len(num_cols)):\n",
        "        for j in range(i+1,len(num_cols)):\n",
        "                if np.abs(corr_matrix.iloc[i,j]) > corr_th:\n",
        "\n",
        "                    corr_i = np.abs(np.corrcoef(X[num_cols[i]],y)[0,1])\n",
        "                    corr_j = np.abs(np.corrcoef(X[num_cols[j]],y)[0,1])\n",
        "                    \n",
        "                    if corr_i >= corr_j:\n",
        "                        corr_cols.append(num_cols[j])\n",
        "                    else:\n",
        "                        corr_cols.append(num_cols[i])\n",
        "    return list(set(corr_cols))\n",
        "\n",
        "to_drop=find_corr_cols(X_train,y_train, num_cols ,0.7)\n",
        "X_train = X_train.drop(to_drop, axis=1)\n",
        "X_test = X_test.drop(to_drop, axis=1)\n",
        "print(to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209f9604",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "209f9604",
        "outputId": "5b19ae0c-32f1-4b40-b3a2-cc3cb6379e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['MinTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'RISK_MM']\n",
            "['WindDir3pm', 'WindGustDir', 'RainToday', 'WindDir9am']\n"
          ]
        }
      ],
      "source": [
        "cols = X_train.columns\n",
        "num_cols = list(X_train.describe().columns)\n",
        "cat_cols = list(set(cols)-set(num_cols))\n",
        "print(num_cols)\n",
        "print(cat_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97724305",
      "metadata": {
        "id": "97724305"
      },
      "outputs": [],
      "source": [
        "def outliers_ths(X, th):\n",
        "    desc = X.describe()\n",
        "    Q1 = desc.loc['25%',:]\n",
        "    Q3 = desc.loc['75%',:]\n",
        "    IQR = Q3 - Q1\n",
        "    Upper = Q3 + th*IQR.values\n",
        "    Lower = Q1 - th*IQR.values\n",
        "    return Upper, Lower\n",
        "Upper , Lower = outliers_ths(traindf[num_cols], 5)\n",
        "\n",
        "for i in range(len(num_cols)):\n",
        "            col = num_cols[i]\n",
        "            X_train.loc[X_train[col]<Lower[i], col] = Lower[i]\n",
        "            X_train.loc[X_train[col]>Upper[i], col] = Upper[i]\n",
        "            \n",
        "            X_test.loc[X_test[col]<Lower[i], col] = Lower[i]\n",
        "            X_test.loc[X_test[col]>Upper[i], col] = Upper[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9747b05e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9747b05e",
        "outputId": "6a82fc26-715c-45f1-c61e-f0a2ebdc9fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Rainfall', 'WindSpeed9am', 'RISK_MM']\n"
          ]
        }
      ],
      "source": [
        "def skewed_cols(X, num_cols):\n",
        "    skewed = []\n",
        "    for i in num_cols:\n",
        "            var_avg = X[i].mean()\n",
        "            var_std = X[i].std()\n",
        "            sk = (((X[i]-var_avg)/var_std)**3).sum() / X.shape[0]\n",
        "            if  np.abs(sk) > 1 :\n",
        "                skewed.append(i)\n",
        "    return skewed\n",
        "\n",
        "log_trans = skewed_cols(X_train[num_cols],num_cols)\n",
        "for i in log_trans:\n",
        "    X_train[i] = np.log(1+np.abs(X_train[i]))\n",
        "    X_test[i] = np.log(1+np.abs(X_test[i]))\n",
        "print(log_trans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69df5b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a69df5b0",
        "outputId": "738b1ae0-4180-410b-8fbf-12a0492158c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Scaler:  ['WindGustSpeed', 'Pressure3pm']\n",
            "Min Max Scaler:  ['MinTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Cloud9am', 'Cloud3pm', 'RISK_MM']\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import shapiro\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "def sh_test(X, num_cols, shapiro_alpha):\n",
        "    gaussian = []\n",
        "    non_gaussian = []\n",
        "\n",
        "    for i in num_cols:\n",
        "        if shapiro(np.array(X[i].sample(100,random_state =0)))[1] > shapiro_alpha:\n",
        "            gaussian.append(i)\n",
        "        else: \n",
        "            non_gaussian.append(i)\n",
        "    return gaussian, non_gaussian\n",
        "gaussian, non_gaussian = sh_test(X_train, num_cols, 0.05)\n",
        "\n",
        "if len(gaussian) >0:    \n",
        "    StandardScaler1 = StandardScaler()\n",
        "    X_train[gaussian] = StandardScaler1.fit_transform(X_train[gaussian])\n",
        "    X_test[gaussian] = StandardScaler1.transform(X_test[gaussian]) \n",
        "if len(non_gaussian) >0:\n",
        "    MinMaxScaler1 = MinMaxScaler()\n",
        "    X_train[non_gaussian] = MinMaxScaler1.fit_transform(X_train[non_gaussian])\n",
        "    X_test[non_gaussian] = MinMaxScaler1.transform(X_test[non_gaussian]) \n",
        "print('Standard Scaler: ' ,gaussian)\n",
        "print('Min Max Scaler: ', non_gaussian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb4ba24",
      "metadata": {
        "id": "adb4ba24"
      },
      "outputs": [],
      "source": [
        "#encoding the categorical variables # one hot encoding , binary encoding (only for rain today)\n",
        "X_train['RainToday'] =(X_train['RainToday']=='Yes').astype(int)\n",
        "X_test['RainToday'] =(X_test['RainToday']=='Yes').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30a0a48",
      "metadata": {
        "id": "f30a0a48"
      },
      "outputs": [],
      "source": [
        "OHE = list(set(cat_cols)-set(['RainToday']))\n",
        "for i in range(len(OHE)):\n",
        "    nominal_vals= X_train[OHE[i]].unique()\n",
        "    for j in nominal_vals:\n",
        "        col ='{}_{}'.format(OHE[i],j)   \n",
        "        X_train.loc[X_train[OHE[i]]==j,col] =1\n",
        "        X_train[col] = X_train[col].fillna(0).astype(int)\n",
        "        \n",
        "        X_test.loc[X_test[OHE[i]]==j,col] =1\n",
        "        X_test[col] = X_test[col].fillna(0).astype(int)\n",
        "        \n",
        "    X_train = X_train.drop(OHE[i] , axis=1)\n",
        "    X_test = X_test.drop(OHE[i] , axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a8bc6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a8bc6b",
        "outputId": "08eba428-978e-461e-a32e-4bbd9a20fb41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mindatory class size is 0.183 from the data set \n"
          ]
        }
      ],
      "source": [
        "# data imbalance \n",
        "print('mindatory class size is {:.3} from the data set '.format (y_train.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6296b14e",
      "metadata": {
        "id": "6296b14e"
      },
      "outputs": [],
      "source": [
        "#under-sampling traindata set\n",
        "under_sampling_size = y_train.sum()\n",
        "\n",
        "X_train_undersampled = X_train[y_train==0].sample(under_sampling_size , replace=False, random_state=1)\n",
        "X_train_undersampled = pd.concat([X_train_undersampled, X_train[y_train==1]], axis=0)\n",
        "\n",
        "y_train_undersampled = np.zeros((X_train_undersampled.shape[0]))\n",
        "y_train_undersampled[under_sampling_size:] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe27300",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfe27300",
        "outputId": "d59354e8-30bb-4ed5-ee34-78eb2da3de27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(262, 61)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed40ae87",
      "metadata": {
        "id": "ed40ae87"
      },
      "source": [
        "__________________________\n",
        "3- Explore the selection of various feature variables for classification. You should include at least one categorical feature.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39bd2ede",
      "metadata": {
        "id": "39bd2ede",
        "outputId": "f7b5638a-a8d5-46a8-d793-ace5a34d036d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "traindf1= X_train[num_cols].copy()\n",
        "traindf1['RainTomorrow']= y_train\n",
        "import seaborn as sns\n",
        "sns.heatmap(traindf1.corr(),cmap = 'RdYlGn')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "687ff2ab",
      "metadata": {
        "id": "687ff2ab"
      },
      "source": [
        "## <font color = darkgreen>it seems that RISK_MM has the highest effect in target variable<br> most of features has no significant effect </font> "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc89ea9",
      "metadata": {
        "id": "1bc89ea9"
      },
      "source": [
        "_________________\n",
        "4- Classify the data using various classification methods explored in ML1 (logistic regression, SVC, Decision trees, SVC, KNN classifier). Explore using different model parameters in the built-in sklearn libraries.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d4cb26",
      "metadata": {
        "id": "37d4cb26"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f79222e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "2f79222e",
        "outputId": "15ca7dbf-58ab-470c-9dd5-e70dfd324c95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Area Under ROC curve : 0.9991319444444444\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "LogReg = LogisticRegression()\n",
        "LogReg.fit(X_train_undersampled, y_train_undersampled)\n",
        "\n",
        "y_proba = LogReg.predict_proba(X_train_undersampled)[:,1]\n",
        "fpr , tpr , ths= roc_curve(y_train_undersampled, y_proba)\n",
        "\n",
        "print('Area Under ROC curve :' , roc_auc_score(y_train_undersampled, y_proba))\n",
        "plt.plot(fpr,tpr);\n",
        "plt.xlabel('False Positive Rate');\n",
        "plt.ylabel('True Positive Rate');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ffbd3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ffbd3d",
        "outputId": "a2b30686-4a2f-488f-f7d1-9092d65f6ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "threshold :  0.8212177893487075\n",
            " train f1 : 0.967741935483871 \n",
            " test f1 0.8571428571428571\n"
          ]
        }
      ],
      "source": [
        "th = ths[np.where(tpr>0.55)[0][0]]\n",
        "print('threshold : ' , th)\n",
        "\n",
        "y_hat_train = ((LogReg.predict_proba(X_train_undersampled)>th)[:,1]).astype(int)\n",
        "\n",
        "train_f1= f1_score(y_train_undersampled, y_hat_train)\n",
        "\n",
        "y_hat_test = ((LogReg.predict_proba(X_test)>th)[:,1]).astype(int)\n",
        "test_f1= f1_score(y_test , y_hat_test)\n",
        "print(' train f1 : {} \\n test f1 {}'.format(train_f1, test_f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8733352c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8733352c",
        "outputId": "fd39608a-de76-43bd-ae59-5452a40cb6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kernal : linear\n",
            "Choosed parameter :\n",
            " C =  3.0     \n",
            " max_test_f1:  1.0\n"
          ]
        }
      ],
      "source": [
        "Cs = np.linspace(1,30,30)\n",
        "\n",
        "kernals = ['linear', 'poly','rbf']\n",
        "print('kernal : {}'.format(kernals[0]))\n",
        "#print ('              C      train_f1      test_f1')\n",
        "\n",
        "max_f1 = 0\n",
        "choosed_c = 0\n",
        "\n",
        "for c in Cs:\n",
        "    model = SVC(C =c , kernel=kernals [0])\n",
        "    model.fit(X_train_undersampled , y_train_undersampled)\n",
        "    y_hat = model.predict(X_train_undersampled)\n",
        "    train_f1= f1_score(y_train_undersampled , y_hat)\n",
        "\n",
        "    y_hat_test = model.predict(X_test)\n",
        "    test_f1= f1_score(y_test , y_hat_test)\n",
        "    \n",
        "    if test_f1 > max_f1:\n",
        "        max_f1 = test_f1 \n",
        "        choosed_c = c\n",
        "\n",
        " #   print('              ',\"{:.3}\".format(c),'        ',\"{:.3}\".format(train_f1),\n",
        "  #        '      ','     ',\"{:.3}\".format(test_f1)  )\n",
        "print('Choosed parameter :\\n C = ',choosed_c , '    \\n max_test_f1: ',max_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81779e37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "81779e37",
        "outputId": "51760d18-83d2-433d-e985-f4b2ce0aa537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kernal : poly\n",
            "Choosed parameters :\n",
            "  {'c': 1.0, 'degree': 7, 'gamma': 0.0001}     \n",
            " max_test_f1:  0.3793103448275862\n"
          ]
        }
      ],
      "source": [
        "print('kernal : {}'.format(kernals[1]))\n",
        "#print ('              C    d    gamma      train_f1   test_f1')\n",
        "Degree = [2,3,4,5,6,7]\n",
        "g  = .0001\n",
        "max_f1 = 0\n",
        "choosed_parameters_poly ={'c':0,'degree':0,'gamma':0}\n",
        "for i in range(5):\n",
        "    for d in Degree: \n",
        "        for c in Cs:\n",
        "            model = SVC(C =c , kernel=kernals[1], degree=d , gamma =g )\n",
        "            model.fit(X_train_undersampled , y_train_undersampled)\n",
        "            y_hat = model.predict(X_train_undersampled)\n",
        "            train_f1= f1_score(y_train_undersampled , y_hat)\n",
        "\n",
        "            y_hat_test = model.predict(X_test)\n",
        "            test_f1= f1_score(y_test , y_hat_test)\n",
        "\n",
        "            if test_f1 >max_f1:\n",
        "                max_f1 = test_f1\n",
        "                choosed_parameters_poly['c']=c\n",
        "                choosed_parameters_poly['degree']=d\n",
        "                choosed_parameters_poly['gamma']=g\n",
        "\n",
        " #           print('            ',\"{:.3}\".format(c),'  ',d,' ',\"{:.4}\".format(g),'          ',\"{:.3}\".format(train_f1),\n",
        "  #                '     ',\"{:.3}\".format(test_f1)  )\n",
        "    g = g+0.0005\n",
        "\n",
        "print('Choosed parameters :\\n ', choosed_parameters_poly,'    \\n max_test_f1: ',max_f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6661a0a8",
      "metadata": {
        "id": "6661a0a8",
        "outputId": "774e0ca1-a3c0-4790-9afd-6253dbcda78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kernal : rbf\n",
            "Choosed parameters :\n",
            "  {'c': 2.0, 'gamma': 0.040100000000000004}     \n",
            " max_test_f1:  0.8571428571428571\n"
          ]
        }
      ],
      "source": [
        "print('kernal : {}'.format(kernals[2]))\n",
        "#print ('              C    gamma      train_f1     test_f1')\n",
        "\n",
        "g  = .0001\n",
        "max_f1 = 0\n",
        "gammas = []\n",
        "F1_score=[]\n",
        "choosed_parameters_rbf ={'c':0,'gamma':0}\n",
        "for i in range(20): \n",
        "    gammas.append(g)\n",
        "    f1 = []\n",
        "    for c in Cs:\n",
        "        model = SVC(C =c , kernel=kernals[2] , gamma =g )\n",
        "        model.fit(X_train_undersampled , y_train_undersampled)\n",
        "        y_hat = model.predict(X_train_undersampled)\n",
        "        train_f1= f1_score(y_train_undersampled , y_hat)\n",
        " \n",
        "        y_hat_test = model.predict(X_test)\n",
        "        test_f1= f1_score(y_test , y_hat_test)\n",
        "        f1.append([train_f1 , test_f1])\n",
        "        if test_f1 >max_f1:\n",
        "            max_f1 = test_f1\n",
        "            choosed_parameters_rbf['c']=c\n",
        "            choosed_parameters_rbf['gamma']=g\n",
        "    F1_score.append(f1)\n",
        " #       print('            ',\"{:.3}\".format(c),'  ',\"{:.4}\".format(g),'         ',\"{:.3}\".format(train_f1),\n",
        "  #            '     ',\"{:.3}\".format(test_f1)  )\n",
        "    g = g+0.04\n",
        "\n",
        "print('Choosed parameters :\\n ', choosed_parameters_rbf,'    \\n max_test_f1: ',max_f1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6d6886",
      "metadata": {
        "id": "3d6d6886",
        "outputId": "34688dbd-e92e-4c1e-b783-f7a6529f7ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choosed parameters for Decision Tree model : \n",
            "{'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 4, 'max_leaf_nodes': 20, 'ccp_alpha': 0.001}\n",
            "test_f1:  1.0\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree \n",
        "\n",
        "max_f1 = 0\n",
        "choosedDT = {}\n",
        "for i in range(3,100):\n",
        "    DT = DecisionTreeClassifier(max_depth= i , random_state = 2022)\n",
        "    DT.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, DT.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedDT['max_depth'] = i\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(2,100):\n",
        "    DT = DecisionTreeClassifier(max_depth= choosedDT['max_depth'],min_samples_split=i , random_state = 2022)\n",
        "    DT.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, DT.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedDT['min_samples_split'] = i\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(1,100):\n",
        "    DT = DecisionTreeClassifier(max_depth= choosedDT['max_depth'],min_samples_split=choosedDT['min_samples_split'] ,\n",
        "                                min_samples_leaf=i , random_state = 2022)\n",
        "    DT.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, DT.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedDT['min_samples_leaf'] = i\n",
        "\n",
        "max_f1=0\n",
        "for i in range(1,X_train.shape[1]+1):\n",
        "    DT = DecisionTreeClassifier(max_depth= choosedDT['max_depth'],min_samples_split=choosedDT['min_samples_split'] ,\n",
        "                                min_samples_leaf=choosedDT['min_samples_leaf'], max_features= i, random_state = 2022)\n",
        "    DT.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, DT.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedDT['max_features'] = i\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(2,1000):\n",
        "    DT = DecisionTreeClassifier(max_depth= choosedDT['max_depth'],min_samples_split=choosedDT['min_samples_split'] ,\n",
        "                                min_samples_leaf=choosedDT['min_samples_leaf'], max_features= choosedDT['max_features'],\n",
        "                                max_leaf_nodes= i*10 , random_state = 2022)\n",
        "    DT.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, DT.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedDT['max_leaf_nodes'] = i*10\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(1,100):\n",
        "    DT = DecisionTreeClassifier(max_depth= choosedDT['max_depth'],min_samples_split=choosedDT['min_samples_split'] ,\n",
        "                                min_samples_leaf=choosedDT['min_samples_leaf'], max_features= choosedDT['max_features'],\n",
        "                                ccp_alpha=0.001 *i , random_state = 2022)\n",
        "    DT.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, DT.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedDT['ccp_alpha'] = 0.001*i\n",
        "        \n",
        "print('Choosed parameters for Decision Tree model : ')\n",
        "print(choosedDT)\n",
        "DT = DecisionTreeClassifier(max_depth= choosedDT['max_depth'],min_samples_split=choosedDT['min_samples_split'] ,\n",
        "                                min_samples_leaf=choosedDT['min_samples_leaf'], max_features= choosedDT['max_features'],\n",
        "                                random_state = 2022)\n",
        "DT.fit(X_train, y_train)\n",
        "print('test_f1: ' , f1_score(y_test, DT.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf9ca702",
      "metadata": {
        "id": "cf9ca702",
        "outputId": "6cdc8ab7-8ce8-4bda-c44c-2dd5fa6d41ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrap = False\n",
            "test_f1:  0.9565217391304348\n",
            "Bootstrap = True\n",
            "test_f1:  1.0\n",
            "Random Forest :  {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 6, 'max_leaf_nodes': 200, 'ccp_alpha': 0.001, 'n_estimators': 35}\n",
            "test_f1:  1.0\n"
          ]
        }
      ],
      "source": [
        "max_f1 = 0\n",
        "choosedRF = {}\n",
        "for i in range(3,100):\n",
        "    RF = RandomForestClassifier(max_depth= i , random_state = 2022)\n",
        "    RF.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, RF.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedRF['max_depth'] = i\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(2,100):\n",
        "    RF = RandomForestClassifier(max_depth= choosedRF['max_depth'],min_samples_split=i , random_state = 2022)\n",
        "    RF.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, RF.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedRF['min_samples_split'] = i\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(1,100):\n",
        "    RF = RandomForestClassifier(max_depth= choosedRF['max_depth'],min_samples_split=choosedRF['min_samples_split'] ,\n",
        "                                min_samples_leaf=i , random_state = 2022)\n",
        "    RF.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, RF.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedRF['min_samples_leaf'] = i\n",
        "        \n",
        "max_f1 = 0\n",
        "for i in range(1,X_train.shape[1]+1):\n",
        "    RF = RandomForestClassifier(max_depth= choosedRF['max_depth'], min_samples_split=choosedRF['min_samples_split'] ,\n",
        "                                min_samples_leaf=choosedRF['min_samples_leaf'], max_features= i, random_state = 2022)\n",
        "    RF.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, RF.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedRF['max_features'] = i\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(2,100):\n",
        "    RF = RandomForestClassifier(max_depth= choosedRF['max_depth'],min_samples_split=choosedRF['min_samples_split'] ,\n",
        "                                min_samples_leaf=choosedRF['min_samples_leaf'], max_features= choosedRF['max_features'],\n",
        "                                max_leaf_nodes= i*100 , random_state = 2022)\n",
        "    RF.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, RF.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedRF['max_leaf_nodes'] = i*100\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(1,100):\n",
        "    RF = RandomForestClassifier(max_depth= choosedRF['max_depth'],min_samples_split=choosedRF['min_samples_split'] ,\n",
        "                                min_samples_leaf=choosedRF['min_samples_leaf'], max_features= choosedRF['max_features'],\n",
        "                                ccp_alpha=0.001 *i , random_state = 2022)\n",
        "    RF.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, RF.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedRF['ccp_alpha'] = 0.001*i\n",
        "\n",
        "max_f1 = 0\n",
        "for i in range(1,100):\n",
        "    RF = RandomForestClassifier(max_depth= choosedRF['max_depth'],min_samples_split=choosedRF['min_samples_split'] ,\n",
        "                                n_estimators = 5*i , random_state = 2022)\n",
        "    RF.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, RF.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedRF['n_estimators'] = 5*i\n",
        "\n",
        "max_f1 = 0\n",
        "max_s = X_train.shape[0]\n",
        "for i in range(100, int(max_s/100)):\n",
        "    RF = RandomForestClassifier(max_depth= choosedRF['max_depth'],min_samples_split=choosedRF['min_samples_split'] ,\n",
        "                                n_estimators = choosedRF['n_estimators'], max_samples=i*100 , random_state = 2022)\n",
        "    RF.fit(X_train , y_train)\n",
        "    test_score = f1_score(y_test, RF.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosedRF['max_samples'] = i*100\n",
        "        \n",
        "        \n",
        "print('Bootstrap = False')\n",
        "RF = RandomForestClassifier(max_depth= choosedRF['max_depth'],min_samples_split=choosedRF['min_samples_split'] ,\n",
        "                            n_estimators = choosedRF['n_estimators'] , bootstrap = False, random_state = 2022)\n",
        "RF.fit(X_train , y_train)\n",
        "test_score = f1_score(y_test, RF.predict(X_test))\n",
        "print('test_f1: ' , test_score)\n",
        "\n",
        "print('Bootstrap = True')\n",
        "RF = RandomForestClassifier(max_depth= choosedRF['max_depth'],min_samples_split=choosedRF['min_samples_split'] ,\n",
        "                            n_estimators = choosedRF['n_estimators'] , bootstrap = True, random_state = 2022)\n",
        "RF.fit(X_train , y_train)\n",
        "test_score = f1_score(y_test, RF.predict(X_test))\n",
        "print('test_f1: ' , test_score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "print('Random Forest : ', choosedRF)\n",
        "print('test_f1: ' , test_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a8fdaf8",
      "metadata": {
        "id": "2a8fdaf8",
        "outputId": "4631cbf6-b8b1-4b0b-90f1-6393930efd36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p      train_fl_score      test_f1_socre\n",
            "1          0.847            0.762\n",
            "2          0.747            0.667\n",
            "3          0.659            0.636\n",
            "4          0.675            0.571\n",
            "{'p': 1}\n",
            "test_f1:  0.761904761904762\n"
          ]
        }
      ],
      "source": [
        "#KNN\n",
        "#a)tuning of different p values in the Minkowski distance metric \n",
        "choosed ={}\n",
        "max_f1 = 0\n",
        "print ( 'p      train_fl_score      test_f1_socre')\n",
        "for i in range(1,5):\n",
        "    KNN = KNeighborsClassifier(metric='minkowski', p =i )\n",
        "    KNN.fit(X_train, y_train)\n",
        "    train_score= f1_score(y_train, KNN.predict(X_train))\n",
        "    test_score = f1_score(y_test, KNN.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosed['p'] = i\n",
        "    print('{}          {:.3}            {:.3}'.format(i, train_score, test_score))\n",
        "print(choosed)\n",
        "print('test_f1: ' , max_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660adbce",
      "metadata": {
        "id": "660adbce",
        "outputId": "926a5888-3751-4412-e0ec-1f739420ce0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'p': 1, 'neighbors': 5}\n",
            "test_f1:  0.761904761904762\n"
          ]
        }
      ],
      "source": [
        "#b. try different N_neighbors\n",
        "max_f1 = 0\n",
        "for i in range(1,50):\n",
        "    KNN = KNeighborsClassifier(metric='minkowski', p =choosed['p'],n_neighbors = i*5)\n",
        "    KNN.fit(X_train, y_train)\n",
        "    test_score = f1_score(y_test, KNN.predict(X_test))\n",
        "    if test_score > max_f1:\n",
        "        max_f1 = test_score\n",
        "        choosed['neighbors'] = i*5\n",
        "print(choosed)\n",
        "print('test_f1: ' , max_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c9ca3a9",
      "metadata": {
        "id": "3c9ca3a9",
        "outputId": "7c02620a-20c7-4d7c-81ba-0e2074a375d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights:  uniform\n",
            "train f1_score :  0.7469879518072288\n",
            "test f1_score:  0.6666666666666666\n",
            "weights:  distance\n",
            "train f1_score :  1.0\n",
            "test f1_score:  0.6666666666666666\n"
          ]
        }
      ],
      "source": [
        "#c. Try ‘uniform’ and ‘distance’ options in the weights hyper-parameter\n",
        "weights = ['uniform' , 'distance']\n",
        "max_f1 = 0\n",
        "for w in weights: \n",
        "    print('weights: ' ,w )\n",
        "    KNN = KNeighborsClassifier(weights = w)\n",
        "    KNN.fit(X_train, y_train)\n",
        "    test_f1 = f1_score(y_test, KNN.predict(X_test))\n",
        "    if test_f1 > max_f1:\n",
        "        max_f1 = test_f1\n",
        "        choosed['weights'] = w\n",
        "    print('train f1_score : ', f1_score(y_train, KNN.predict(X_train)))\n",
        "    print('test f1_score: ',test_f1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce8c114",
      "metadata": {
        "id": "5ce8c114",
        "outputId": "bd3907cd-2479-42bc-bfbe-1f509704d596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choosed Parameters for KNN model:\n",
            "{'p': 1, 'neighbors': 5, 'weights': 'uniform'}\n",
            "test f1_score:  0.761904761904762\n"
          ]
        }
      ],
      "source": [
        "#Use different combinations of p and N_neighbors to find the best hyper-parameters that best classify the test data\n",
        "print('Choosed Parameters for KNN model:')\n",
        "print(choosed)\n",
        "\n",
        "KNN = KNeighborsClassifier(metric='minkowski', p =choosed['p'],n_neighbors = choosed['neighbors'],\n",
        "                           weights = choosed['weights'])\n",
        "KNN.fit(X_train, y_train)\n",
        "test_score = f1_score(y_test, KNN.predict(X_test))\n",
        "print('test f1_score: ',test_score )   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e34e421",
      "metadata": {
        "id": "0e34e421"
      },
      "source": [
        "_______________________\n",
        "5- Explore the use of your own implementations of each Model. Comment on your results.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83427d7f",
      "metadata": {
        "id": "83427d7f"
      },
      "outputs": [],
      "source": [
        "def initialize(X, bias = True):\n",
        "    if bias:\n",
        "        weights = np.zeros((X.shape[1]+1,1))\n",
        "        X = np.c_[np.ones((X.shape[0],1)),X]\n",
        "    else:\n",
        "        weights = np.zeros((X.shape[1],1))\n",
        "    return weights,X\n",
        "\n",
        "def sigmoid(z):\n",
        "    sig = 1/(1 + np.e**(-z))\n",
        "    return sig\n",
        "\n",
        "def cost(X, y, theta):\n",
        "    z = np.dot(X,theta)\n",
        "    cost0 = y.T.dot(np.log(sigmoid(z)))\n",
        "    cost1 = (1-y).T.dot(np.log(1-sigmoid(z)))\n",
        "    cost = -((cost1 + cost0))/len(y) \n",
        "    return cost\n",
        "\n",
        "def fit(X, y, lr=0.001, bias = True, max_iterations=100):\n",
        "    params,X = initialize(X, bias)\n",
        "    for i in range(max_iterations):\n",
        "        params = params - lr * np.dot(X.T, sigmoid(np.dot(X,params)) - np.reshape(y,(len(y),1)))\n",
        "    return params\n",
        "\n",
        "def predict(X, optimum_weights, bias = True, threshold = 0.5):\n",
        "    z = np.dot(initialize(X, bias)[1], optimum_weights)\n",
        "    preds = []\n",
        "    for i in sigmoid(z):\n",
        "        if i>threshold:\n",
        "            preds.append(1)\n",
        "        else:\n",
        "            preds.append(0)\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94718f06",
      "metadata": {
        "id": "94718f06"
      },
      "outputs": [],
      "source": [
        "bias = True\n",
        "max_iterations = 100\n",
        "lr = 0.001\n",
        "optimum_weights = fit(X_train, np.array(y_train), lr = 0.001, bias = bias, max_iterations = max_iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98373fcb",
      "metadata": {
        "id": "98373fcb"
      },
      "outputs": [],
      "source": [
        "test_preds = predict(X_test, optimum_weights, bias = bias, threshold = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a334a452",
      "metadata": {
        "id": "a334a452",
        "outputId": "401a06be-b17b-42bf-e61c-4dd7b496dedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score (test data) , (from scratch) :  0.8571428571428571\n",
            "f1_score (test data) , (sklearn) :  0.8571428571428571\n"
          ]
        }
      ],
      "source": [
        "y_hat_test = ((LogReg.predict_proba(X_test)>th)[:,1]).astype(int)\n",
        "test_f1= f1_score(y_test , y_hat_test)\n",
        "print('f1_score (test data) , (from scratch) : ', f1_score(y_test , test_preds))\n",
        "print('f1_score (test data) , (sklearn) : ',test_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "947cbde7",
      "metadata": {
        "id": "947cbde7",
        "outputId": "90d97e17-65b0-4802-98e0-6df8424a2cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "from scratch f1_score :  0.4210526315789474\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree\n",
        "class Node():\n",
        "    def __init__(self, feature_index = None, threshold = None, left = None, right = None, info_gain = None, value = None):\n",
        "        # for decision nodes (internal nodes)\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "\n",
        "        # for leaf node\n",
        "        self.value = value\n",
        "\n",
        "class DecisionTreeClassifierFromScratch():\n",
        "  def __init__(self, min_samples_split = 2, max_depth = 2, max_features_per_split = 3, criterion = 'gini'):\n",
        "    self.root = None\n",
        "    self.max_features_per_split = max_features_per_split\n",
        "    self.criterion = criterion\n",
        "\n",
        "    # set the stopping conditions\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.max_depth = max_depth\n",
        "    \n",
        "  def gini_index(self, y):\n",
        "    class_labels = np.unique(y)\n",
        "    gini = 0\n",
        "    for cls in class_labels:\n",
        "      p_cls = len(y[y == cls])/len(y)\n",
        "      gini += (p_cls ** 2)\n",
        "    return 1 - gini\n",
        "\n",
        "  def entropy(self, y):\n",
        "    class_labels = np.unique(y)\n",
        "    entropy = 0 \n",
        "    for cls in class_labels:\n",
        "      p_cls = len(y[y == cls])/len(y)\n",
        "      entropy += -p_cls * np.log2(p_cls)\n",
        "    return entropy\n",
        "\n",
        "  def information_gain(self, parent, l_child, r_child, mode):\n",
        "    ## parent: the list of ground truth labels for all the points in the region of the parent node\n",
        "    ## l_child : the list of ground truth labels for all the points in the region l_child\n",
        "    weight_l = len(l_child)/len(parent)\n",
        "    weight_r = len(r_child)/len(parent)\n",
        "\n",
        "    if mode == 'gini':\n",
        "      gain = self.gini_index(parent) - ((weight_l * self.gini_index(l_child)) + (weight_r * self.gini_index(r_child)))\n",
        "    else:\n",
        "      gain = self.entropy(parent) - ((weight_l * self.entropy(l_child)) + (weight_r * self.entropy(r_child)))\n",
        "    return gain\n",
        "\n",
        "  def split(self, dataset, feature_index, threshold):\n",
        "    dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
        "    dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
        "    return dataset_left, dataset_right\n",
        "\n",
        "  def get_best_split(self, dataset, num_samples, num_features, max_features_per_split, mode):\n",
        "    # define a dictionary to store the best split\n",
        "    best_split = {}\n",
        "    max_info_gain = -float(\"inf\")\n",
        "\n",
        "    # loop over a random sample of the features\n",
        "    random_features_indices = np.random.choice(num_features, size = max_features_per_split, replace = False)\n",
        "    for feature_index in random_features_indices:\n",
        "      feature_values = dataset[ :, feature_index]\n",
        "      possible_thresholds = np.unique(feature_values)\n",
        "\n",
        "      # loop over all possible split values (thresholds) for the current feature\n",
        "      for threshold in possible_thresholds:\n",
        "        dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "        # making sure that the current split has left and right datasets \n",
        "        if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
        "          y_parent, y_left_child, y_right_child = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "          curr_info_gain = self.information_gain(y_parent, y_left_child, y_right_child, mode = mode)\n",
        "          if curr_info_gain > max_info_gain:\n",
        "            best_split['feature_index'] = feature_index\n",
        "            best_split['threshold'] = threshold\n",
        "            best_split['dataset_left'] = dataset_left\n",
        "            best_split['dataset_right'] = dataset_right\n",
        "            best_split['info_gain'] = curr_info_gain\n",
        "            max_info_gain = curr_info_gain\n",
        "    return best_split\n",
        "\n",
        "  def calculate_leaf_value(self, Y):\n",
        "    Y = list(Y)\n",
        "    return max(Y, key = Y.count)\n",
        "\n",
        "  def build_tree(self, dataset, curr_depth = 0):\n",
        "    # recursive function to build the tree\n",
        "    X, Y = dataset[:, :-1], dataset[:, -1]\n",
        "    num_samples, num_features = np.shape(X)\n",
        "    # we will split until the stopping coditions are met\n",
        "    if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
        "      # getting the best split; it returns a dictionary\n",
        "      best_split = self.get_best_split(dataset, num_samples, num_features, self.max_features_per_split, self.criterion)\n",
        "      # check if the information gain after the best split is positive\n",
        "      if best_split['info_gain'] > 0:\n",
        "        left_subtree = self.build_tree(best_split['dataset_left'], curr_depth + 1)\n",
        "        right_subtree = self.build_tree(best_split['dataset_right'], curr_depth + 1)\n",
        "        return Node(feature_index = best_split['feature_index'], threshold = best_split['threshold'], \n",
        "                    left = left_subtree, right = right_subtree, info_gain = best_split['info_gain'], value = None)\n",
        "        \n",
        "    # compute the leaf node only if we are out of the stopping condition\n",
        "    leaf_value = self.calculate_leaf_value(Y) \n",
        "    # return leaf node\n",
        "    return Node(value = leaf_value)\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    dataset = np.hstack((X, Y))\n",
        "    self.root = self.build_tree(dataset)\n",
        "\n",
        "  def make_prediction(self, x, tree):\n",
        "    if tree.value != None: \n",
        "      return tree.value\n",
        "    feature_val = x[tree.feature_index]\n",
        "    if feature_val <= tree.threshold:\n",
        "      return self.make_prediction(x, tree.left)\n",
        "    else:\n",
        "      return self.make_prediction(x, tree.right)\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = [self.make_prediction(x, self.root) for x in X.values]\n",
        "    return predictions\n",
        "\n",
        "  def print_tree(self, tree=None, indent=\" \"):\n",
        "        ''' function to print the tree '''\n",
        "        \n",
        "        if not tree:\n",
        "            tree = self.root\n",
        "\n",
        "        if tree.value is not None:\n",
        "            print(tree.value)\n",
        "\n",
        "        else:\n",
        "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
        "            print(\"%sleft:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.left, indent + indent)\n",
        "            print(\"%sright:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.right, indent + indent)\n",
        "\n",
        "            \n",
        "classifier = DecisionTreeClassifierFromScratch(min_samples_split = 3, max_depth = 3, max_features_per_split = 2, criterion= 'gini')\n",
        "classifier.fit(X_train[X_train.columns[:10]], np.array(y_train).reshape(-1,1))\n",
        "\n",
        "Y_pred = classifier.predict(X_test[X_train.columns[:10]])\n",
        "\n",
        "print('from scratch f1_score : ', f1_score(y_test, Y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a36e54",
      "metadata": {
        "id": "70a36e54",
        "outputId": "4a47ec75-ce80-476e-e4ce-3024265e6594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1_score for test data(from scratch):  0.6363636363636365\n",
            "F1_score for test data(sklearn):  0.6363636363636365\n"
          ]
        }
      ],
      "source": [
        "# K neighbours \n",
        "from scipy.stats import mode \n",
        "class K_Nearest_Neighbors_Classifier() : \n",
        "      \n",
        "    def __init__( self, K ) :\n",
        "          self.K = K\n",
        "          \n",
        "    # Function to store training set\n",
        "          \n",
        "    def fit( self, X_train, Y_train ) :\n",
        "        self.X_train = X_train\n",
        "        self.Y_train = Y_train  \n",
        "        # no_of_training_examples, no_of_features\n",
        "        self.m, self.n = X_train.shape\n",
        "      \n",
        "\n",
        "    def predict( self, X_test ) : \n",
        "        self.X_test = X_test\n",
        "        # no_of_test_examples, no_of_features\n",
        "        self.m_test, self.n = X_test.shape\n",
        "        # initialize Y_predict\n",
        "        Y_predict = np.zeros( self.m_test )\n",
        "          \n",
        "        for i in range( self.m_test ) :\n",
        "            x = self.X_test[i]\n",
        "            # find the K nearest neighbors from current test example\n",
        "            neighbors = np.zeros( self.K )\n",
        "            neighbors = self.find_neighbors( x )\n",
        "            # most frequent class in K neighbors\n",
        "            Y_predict[i] = mode( neighbors )[0][0]    \n",
        "              \n",
        "        return Y_predict\n",
        "      \n",
        "    # Function to find the K nearest neighbors to current test example\n",
        "            \n",
        "    def find_neighbors( self, x ) :\n",
        "          \n",
        "        # calculate all the euclidean distances between current \n",
        "        # test example x and training set X_train\n",
        "        euclidean_distances = np.zeros( self.m )\n",
        "        for i in range( self.m ) :\n",
        "            d = self.euclidean( x, self.X_train[i] )\n",
        "            euclidean_distances[i] = d\n",
        "        # sort Y_train according to euclidean_distance_array and \n",
        "        # store into Y_train_sorted\n",
        "        inds = euclidean_distances.argsort()\n",
        "        Y_train_sorted = self.Y_train[inds]\n",
        "          \n",
        "        return Y_train_sorted[:self.K]\n",
        "      \n",
        "    # Function to calculate euclidean distance\n",
        "              \n",
        "    def euclidean( self, x, x_train ) :\n",
        "          \n",
        "        return np.sqrt( np.sum( np.square( x - x_train ) ) )\n",
        "\n",
        "\n",
        "# Splitting dataset into train and test set\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = X_train.values , X_test.values, y_train.values, y_test.values\n",
        "\n",
        "# Model training\n",
        "\n",
        "model = K_Nearest_Neighbors_Classifier( K = 3 )\n",
        "\n",
        "model.fit( X_train, Y_train )\n",
        "\n",
        "model1 = KNeighborsClassifier( n_neighbors = 3 )\n",
        "\n",
        "model1.fit( X_train, Y_train )\n",
        "\n",
        "# Prediction on test set\n",
        "\n",
        "Y_pred = model.predict( X_test )\n",
        "\n",
        "Y_pred1 = model1.predict( X_test )\n",
        "\n",
        "print('F1_score for test data(from scratch): ', f1_score(Y_test , Y_pred))\n",
        "print('F1_score for test data(sklearn): ', f1_score(Y_test , Y_pred1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66fded3e",
      "metadata": {
        "id": "66fded3e"
      },
      "outputs": [],
      "source": [
        "# SVC\n",
        "X = X_train\n",
        "y = np.array(y_train).reshape(-1,1)\n",
        "#Initializing values and computing H. Note the 1. to force to float type\n",
        "m,n = X.shape\n",
        "y = y * 1.\n",
        "X_dash = y * X\n",
        "H = np.dot(X_dash , X_dash.T) * 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df0ee836",
      "metadata": {
        "id": "df0ee836"
      },
      "outputs": [],
      "source": [
        "#Converting into cvxopt format\n",
        "from cvxopt import matrix as cvxopt_matrix\n",
        "from cvxopt import solvers as cvxopt_solvers\n",
        "\n",
        "P = cvxopt_matrix(H)\n",
        "q = cvxopt_matrix(-np.ones((m, 1)))\n",
        "G = cvxopt_matrix(-np.eye(m))\n",
        "h = cvxopt_matrix(np.zeros(m))\n",
        "A = cvxopt_matrix(y.reshape(1, -1))\n",
        "b = cvxopt_matrix(np.zeros(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Se-v9FBsU_O8",
      "metadata": {
        "id": "Se-v9FBsU_O8"
      },
      "outputs": [],
      "source": [
        "cvxopt_solvers.options['show_progress'] = False\n",
        "sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
        "alphas = np.array(sol['x'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KnroP39aVBcf",
      "metadata": {
        "id": "KnroP39aVBcf"
      },
      "outputs": [],
      "source": [
        "supp_vector = []\n",
        "for j in range(len(alphas)):\n",
        "  current_alpha_value = alphas[j][0]\n",
        "  if (current_alpha_value > 1e-4 ) :\n",
        "    supp_vector.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u7bTj943VDie",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7bTj943VDie",
        "outputId": "2c6cc857-da0d-42c5-ba05-550ba00f7803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alphas =  [9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195 9.8270785e+195 9.8270785e+195\n",
            " 9.8270785e+195 9.8270785e+195]\n",
            "w =  [ 1.40642608e-05  1.17883678e-05  5.64054559e-06 -8.48625504e-07\n",
            "  1.03151645e-05  7.28657329e-06  9.41202934e-06  1.14813143e-06\n",
            "  1.33357631e-05  7.96427538e-06  1.34412602e-05  1.10146202e-05\n",
            "  9.67754803e-06  3.99129941e-06 -1.89416850e-05  2.36107599e-06\n",
            "  7.25681667e-07  2.61037321e-06  6.46477833e-06 -1.70813853e-05\n",
            "  6.80242395e-07  1.13605725e-06  0.00000000e+00  5.63194041e-07\n",
            "  1.08210799e-06  2.34900930e-05  7.01340125e-07  1.89437502e-06\n",
            "  0.00000000e+00  6.36752860e-06 -2.12702198e-05  7.72032574e-06\n",
            "  1.70499128e-06  1.95748983e-06  1.17276847e-06  1.76279068e-06\n",
            "  9.28911702e-07  2.40085316e-06  1.12600073e-06  1.18483935e-06\n",
            "  0.00000000e+00  1.64281114e-06  0.00000000e+00  2.97845715e-06\n",
            "  0.00000000e+00 -1.73242859e-05 -2.08215143e-05  3.72109427e-06\n",
            "  2.85658698e-05  4.16187853e-06  7.19869088e-07  3.33171416e-06\n",
            "  1.92015136e-07  1.79459604e-06  3.21517401e-06  5.63194041e-07\n",
            "  3.67524160e-07  0.00000000e+00  6.73177748e-07  5.17241228e-07\n",
            "  0.00000000e+00]\n",
            "b =  0.0\n"
          ]
        }
      ],
      "source": [
        "# defining a function that calculates the inner summation term (inner loop) of the intercept term\n",
        "def b_calc(Support_vectors_indices, alphas, x_train, y):\n",
        "  outer_sum_term = 0\n",
        "  for s in Support_vectors_indices:\n",
        "    inner_sum_term = 0\n",
        "    for m in Support_vectors_indices:\n",
        "      inner_sum_term += (alphas[m] * y[m] * np.dot(x_train[m], x_train[s]))\n",
        "    outer_sum_term += (y[s] - inner_sum_term)\n",
        "  \n",
        "  return outer_sum_term/len(Support_vectors_indices)\n",
        "  \n",
        "#w parameter in vectorized form\n",
        "w = ((y * alphas).T .dot(X)).reshape(-1,1)\n",
        "\n",
        "#Computing b\n",
        "b = b_calc(supp_vector, alphas.flatten(), X, y.flatten())\n",
        "\n",
        "#Display results\n",
        "print('Alphas = ',alphas[alphas > 1e-4])\n",
        "print('w = ', w.flatten())\n",
        "print('b = ', b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fcd238d",
      "metadata": {
        "id": "5fcd238d"
      },
      "source": [
        "_______\n",
        "6- For each model provide suitable quantitative metrics for assessing the performance of your model based on the required application."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "487e4059",
      "metadata": {
        "id": "487e4059"
      },
      "source": [
        "we use f1_score for each model because the data is imbalance<br> + ROC , ROC_AUC for logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64581299",
      "metadata": {
        "id": "64581299"
      },
      "source": [
        "## <font color = darkgreen > Choosed Models : <br><br> SVC</font>\n",
        "(linear kernal , C =3) <br>\n",
        "##  <font color = darkgreen > Decision Tree(Choosed parameters : </font>\n",
        "{'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 17, 'max_leaf_nodes': 20, 'ccp_alpha': 0.001})\n",
        "##  <font color = darkgreen > Random Forest(Choosed parameters : </font>\n",
        " {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 6, 'max_leaf_nodes': 200, 'ccp_alpha': 0.001, 'n_estimators': 35}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "64581299"
      ],
      "name": "Hayaa_Final_Project_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}